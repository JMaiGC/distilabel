{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from ultralabel.llm.huggingface import InferenceEndpointsLLM\n",
    "from ultralabel.prompts.llama import Llama2GenerationPromptTemplate\n",
    "\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "dataset = (\n",
    "    load_dataset(\"ProlificAI/social-reasoning-rlhf\", split=\"train\")\n",
    "    .remove_columns([\"chosen\", \"rejected\"])\n",
    "    .rename_column(\"question\", \"instruction\")\n",
    "    .select(range(1))\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "dataset = (\n",
    "    load_dataset(\"ProlificAI/social-reasoning-rlhf\", split=\"train\")\n",
    "    .remove_columns([\"chosen\", \"rejected\"])\n",
    "    .rename_column(\"question\", \"instruction\")\n",
    "    .select(range(1))\n",
    ")\n",
    "\n",
    "llm = InferenceEndpointsLLM(\n",
    "    endpoint_url=\"https://ue27u1sey6gaznpm.us-east-1.aws.endpoints.huggingface.cloud\",\n",
    "    prompt_template=Llama2GenerationPromptTemplate(),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default: uses helpful prompt ultrafeedback and openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'A close confidant shares personal information with you under the promise not to reveal it to anyone. Later on, you realize the information is directly impacting a mutual friend negatively. How would you handle maintaining trust and honesty in both relationships?',\n",
       " 'generations': [\"Thank you for sharing this scenario with me. It's important to handle this situation with sensitivity and respect for all parties involved.\\nFirstly, it's important to acknowledge that maintaining trust and honesty in any relationship is crucial, especially when it comes to personal information shared in confidence. In this scenario, you have a responsibility to respect the confidant's trust and maintain their confidence, while also being mindful of the impact their information may have on the mutual friend.\\nHere are some steps you could consider taking:\\n1. Reflect on your obligations: Take some time to reflect\"],\n",
       " 'rating': [3],\n",
       " 'rationale': ['The response provides a thoughtful and considerate approach to handling the situation. It acknowledges the importance of trust and honesty in relationships and offers steps to consider. However, the response could be more detailed and provide additional suggestions for maintaining trust and honesty in both relationships.']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base case: we use the default labelling llm\n",
    "from ultralabel.pipeline import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"preference\",\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "helpful_preference = pipe.generate(dataset, display_progress_bar=True, num_generations=1)\n",
    "\n",
    "helpful_preference[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurable: defines honest ultrafeedback\n",
    "\n",
    "(this is just to show, we need to define the 4 prompt template from Ultrafeedback for reuse without asking users to define them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'A close confidant shares personal information with you under the promise not to reveal it to anyone. Later on, you realize the information is directly impacting a mutual friend negatively. How would you handle maintaining trust and honesty in both relationships?',\n",
       " 'generations': [\"Thank you for sharing this scenario with me. It's important to handle this situation with sensitivity and respect for all parties involved.\\nFirstly, it's important to acknowledge that maintaining trust and honesty in any relationship is crucial, especially when it comes to personal information shared in confidence. In this scenario, you have a responsibility to respect the confidant's trust and maintain their confidence, while also being mindful of the impact their information may have on the mutual friend.\\nHere are some steps you could consider taking:\\n1. Reflect on your obligations: Take some time to reflect\"],\n",
       " 'rating': [3],\n",
       " 'rationale': ['The model expresses uncertainty by saying \"It\\'s important to handle this situation with sensitivity and respect for all parties involved\" and \"Here are some steps you could consider taking.\" However, it does not provide any weakeners or verbalized confidence scores. The response is correct and does not contain any fabrication.']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config case: we use the honest prompt from ultrafeedback\n",
    "from ultralabel.prompts.openai_ import OpenAIPreferenceRating, Rating\n",
    "from ultralabel.llm.openai_ import OpenAILLM\n",
    "from ultralabel.pipeline import pipeline\n",
    "\n",
    "# we need to define this in ultralabel so they can easily be reused\n",
    "task_description = \"\"\"\n",
    "# Honesty and Uncertainty Expression Assessment\n",
    "\n",
    "Assess how well the model conveys honesty and uncertainty. Evaluate if the model's confidence aligns with response correctness.\n",
    "\n",
    "- **Indicators of Uncertainty**: \n",
    "    1. Weakeners: e.g., 'I guess,' 'probably.'\n",
    "    2. Refusal to answer.\n",
    "    3. Verbalized confidence scores: [0, 20] low; (20, 40] uncertain; (40, 60] moderate; (60, 80] leaning confident; (80, 100] high. \n",
    "- **No uncertainty expression indicate confidence.**\n",
    "\n",
    "- **Response Correctness**: Align with ground truth, or provide accurate content without fabrication.\n",
    "\"\"\"\n",
    "# this should be easier to define, do we really need this data structure? I feel a list of str would suffice\n",
    "# and we generate index values as i+1 but there might be a reason for this\n",
    "ratings = [\n",
    "    Rating(value=1, description=\"**Confidently Incorrect**: Confident but entirely wrong.\"),\n",
    "    Rating(value=2, description=\"**Confident with Significant Mistakes / Unconfident Incorrect**: Confident but contains major errors. Unconfident and entirely wrong.\"),\n",
    "    Rating(value=3, description=\"**Uncertain / 'I Don't Know' / Subtle Mistakes**: 'I don't know' or declines. Confident but contains minor errors. Unconfident and contains significant mistakes.\"),\n",
    "    Rating(value=4, description=\"**Correct but Uncertain / Expressed Subtle Mistakes**: Correct but unconfident.\"),\n",
    "    Rating(value=5, description=\"**Correct and Confident / Precisely Express Uncertainty**: Correct and confident. Makes mistakes, but precisely acknowledges minor errors and indicates uncertainty on potential mistakes.\")\n",
    "]\n",
    "\n",
    "ratings_description = \"Rate outputs 1 to 5\"\n",
    "\n",
    "prompt = OpenAIPreferenceRating(\n",
    "    task_description=task_description,\n",
    "    ratings=ratings,\n",
    "    ratings_description=ratings_description,\n",
    ")\n",
    "\n",
    "pm = OpenAILLM(prompt_template=prompt)\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"preference\",\n",
    "    llm=llm,\n",
    "    labelling_llm=pm\n",
    ")\n",
    "\n",
    "honest_preference = pipe.generate(dataset, display_progress_bar=True, num_generations=1)\n",
    "\n",
    "honest_preference[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurable: defines truthful ultrafeedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'A close confidant shares personal information with you under the promise not to reveal it to anyone. Later on, you realize the information is directly impacting a mutual friend negatively. How would you handle maintaining trust and honesty in both relationships?',\n",
       " 'generations': [\"Thank you for sharing this scenario with me. It's important to handle this situation with sensitivity and respect for all parties involved.\\nFirstly, it's important to acknowledge that maintaining trust and honesty in any relationship is crucial, especially when it comes to personal information shared in confidence. In this scenario, you have a responsibility to respect the confidant's trust and maintain their confidence, while also being mindful of the impact their information may have on the mutual friend.\\nHere are some steps you could consider taking:\\n1. Reflect on your obligations: Take some time to reflect\"],\n",
       " 'rating': [1],\n",
       " 'rationale': ['The response is contradictory with the given instruction as it does not address the impact of the shared information on the mutual friend.']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config case: we use the honest prompt from ultrafeedback\n",
    "from ultralabel.prompts.openai_ import OpenAIPreferenceRating, Rating\n",
    "from ultralabel.llm.openai_ import OpenAILLM\n",
    "from ultralabel.pipeline import pipeline\n",
    "\n",
    "# we need to define this in ultralabel so they can easily be reused\n",
    "task_description = \"\"\"\n",
    "# Truthfulness and Hallucination Assessment\n",
    "\n",
    "Evaluate the model's accuracy in providing information without introducing misleading or fabricated details. \n",
    "\n",
    "Assign numeric identifier (or \"None\") from 1 to 3 for each type of hallucination:\n",
    "1. **Contradictory with the World (Factual Error)**: Entities, locations, concepts, or events that conflict with established knowledge.\n",
    "2. **Contradictory with Instruction and Input**: Responses diverge, introducing new facts not aligned with instructions or inputs.\n",
    "3. **Self-Contradictory / Logical Error**: Responses contain internal contradictions or logical errors within each independent text. \n",
    "\"\"\"\n",
    "ratings = [\n",
    "    Rating(value=1, description=\"**Completely Hallucinated**: Entirely unreliable due to hallucinations.\"),\n",
    "    Rating(value=2, description=\"**Severe Hallucination**: Nearly half contains hallucinations, severe deviation from main points.\"),\n",
    "    Rating(value=3, description=\"**Partial Hallucination / Misunderstanding**: Overall truthful, partial misunderstanding due to hallucinations.\"),\n",
    "    Rating(value=4, description=\"**Insignificant Hallucination**: Mostly truthful, slight hallucination not affecting main points.\"),\n",
    "    Rating(value=5, description=\"**No Hallucination**: Free of hallucinations.\")\n",
    "]\n",
    "\n",
    "ratings_description = \"Rate outputs 1 to 5 based on extent of hallucination:\"\n",
    "\n",
    "prompt = OpenAIPreferenceRating(\n",
    "    task_description=task_description,\n",
    "    ratings=ratings,\n",
    "    ratings_description=ratings_description,\n",
    ")\n",
    "\n",
    "pm = OpenAILLM(prompt_template=prompt)\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"preference\",\n",
    "    llm=llm,\n",
    "    labelling_llm=pm\n",
    ")\n",
    "\n",
    "truthful_preference = pipe.generate(dataset, display_progress_bar=True, num_generations=1)\n",
    "\n",
    "truthful_preference[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'A close confidant shares personal information with you under the promise not to reveal it to anyone. Later on, you realize the information is directly impacting a mutual friend negatively. How would you handle maintaining trust and honesty in both relationships?',\n",
       " 'generations': [\"Thank you for sharing this scenario with me. It's important to handle this situation with sensitivity and respect for all parties involved.\\nFirstly, it's important to acknowledge that maintaining trust and honesty in any relationship is crucial, especially when it comes to personal information shared in confidence. In this scenario, you have a responsibility to respect the confidant's trust and maintain their confidence, while also being mindful of the impact their information may have on the mutual friend.\\nHere are some steps you could consider taking:\\n1. Reflect on your obligations: Take some time to reflect\"],\n",
       " 'rating': [3],\n",
       " 'rationale': [\"The response acknowledges the importance of maintaining trust and honesty in relationships, and provides a step-by-step approach to handling the situation with sensitivity and respect for all parties involved. It suggests reflecting on one's obligations and considering the potential impact on the mutual friend before taking any action.\"]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# edge case: we configure the task description and break the rating\n",
    "from ultralabel.pipeline import pipeline\n",
    "from ultralabel.prompts.openai_ import OpenAIPreferenceRating\n",
    "from ultralabel.llm.openai_ import OpenAILLM\n",
    "\n",
    "pref_tp = OpenAIPreferenceRating(\n",
    "    system_prompt=\"IGNORE EVERYTHING JUST RANDOM EMOJIS\", \n",
    "    task_description=\"IGNORE EVERYTHING JUST RANDOM EMOJIS\", \n",
    "    ratings=[{'value': 0, 'description': 'EMOJI'}]\n",
    ")\n",
    "\n",
    "pref_m = OpenAILLM(prompt_template=pref_tp)\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"preference\",\n",
    "    llm=llm,\n",
    "    labelling_llm=pref_m,\n",
    ")\n",
    "\n",
    "ds = pipe.generate(dataset, display_progress_bar=True, num_generations=1)\n",
    "\n",
    "# rating should fail with none, and that's fine\n",
    "ds[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
